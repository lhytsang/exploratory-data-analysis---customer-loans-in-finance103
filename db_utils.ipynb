{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amount: 0.7977492711809002\n",
      "funded_amount: 0.7977492711809002\n",
      "funded_amount_inv: 0.8055737930190515\n",
      "instalment: 0.9894926256453928\n",
      "annual_inc: 8.766706946736596\n",
      "dti: 0.19475459150210536\n",
      "delinq_2yrs: 5.3302689023540095\n",
      "inq_last_6mths: 3.2843306955572724\n",
      "open_accounts: 1.0582172401425745\n",
      "total_accounts: 0.7772746956178468\n",
      "out_prncp: 2.358972868475207\n",
      "out_prncp_inv: 2.3594154508797995\n",
      "total_payment: 1.2572156379380994\n",
      "total_payment_inv: 1.2449396374171213\n",
      "total_rec_prncp: 1.248463242485878\n",
      "total_rec_int: 2.1940362256545747\n",
      "total_rec_late_fee: 13.18644093613826\n",
      "recoveries: 14.133928797708249\n",
      "collection_recovery_fee: 27.505679057194968\n",
      "last_payment_amount: 2.478841250388088\n",
      "collections_12_mths_ex_med: 20.385589060161674\n",
      "\n",
      "\n",
      "\n",
      "loan_amount: 0.7977492711809002\n",
      "funded_amount: 0.7977492711809002\n",
      "funded_amount_inv: 0.8055737930190515\n",
      "instalment: 0.9894926256453928\n",
      "annual_inc: 0.001000646505650805\n",
      "dti: 0.19475459150210536\n",
      "delinq_2yrs: 4.173396558562514\n",
      "inq_last_6mths: 1.3205420452349328\n",
      "open_accounts: 1.0582172401425745\n",
      "total_accounts: 0.7772746956178468\n",
      "out_prncp: 0.544254907373118\n",
      "out_prncp_inv: 0.5442580720656883\n",
      "total_payment: 1.2572156379380994\n",
      "total_payment_inv: 1.2449396374171213\n",
      "total_rec_prncp: 1.248463242485878\n",
      "total_rec_int: -0.0025670731181013868\n",
      "total_rec_late_fee: 13.18644093613826\n",
      "recoveries: 14.133928797708249\n",
      "collection_recovery_fee: -15.120011102790961\n",
      "last_payment_amount: 0.07117611507458599\n",
      "collections_12_mths_ex_med: 20.385589060161674\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import db_utils\n",
    "import yaml, pandas as pd, numpy as np, plotly.express as px\n",
    "from scipy import stats\n",
    "\n",
    "'''\n",
    "Loading the data in the yaml file and saving it as \n",
    "a csv file on the local machine\n",
    "'''\n",
    "\n",
    "with open('credentials.yaml') as file:\n",
    "    credentials_dict = yaml.safe_load(file)\n",
    "    \n",
    "credentials = db_utils.RDSDatabaseConnector(credentials_dict)\n",
    "loan_payments = credentials.initialise_database()\n",
    "credentials.save_file(loan_payments, 'new_file.csv')\n",
    "\n",
    "\n",
    "'''\n",
    "Loading the data and adjusting the data types of each column of the dataframe\n",
    "where needed as well as ensuring the formatting of the data (specifically those \n",
    "that consist of dates) are all the same\n",
    "'''\n",
    "\n",
    "database = db_utils.load_csv('new_file.csv')\n",
    "data_transform = db_utils.DataTransform(database)\n",
    "\n",
    "date_data = ['issue_date', 'earliest_credit_line', 'last_payment_date', 'next_payment_date',\n",
    "             'last_credit_pull_date']\n",
    "\n",
    "categorical_data = ['member_id', 'term', 'int_rate', 'grade', 'sub_grade', 'employment_length', 'home_ownership', 'verification_status', 'loan_status', \n",
    "                    'payment_plan', 'purpose', 'policy_code', 'application_type']\n",
    "\n",
    "non_numeric_data = date_data + categorical_data \n",
    "column_headings = database.columns.values.tolist()\n",
    "numeric_data = [column for column in column_headings if column not in non_numeric_data]\n",
    "\n",
    "for date_column in date_data:\n",
    "    database, date_column = data_transform.date_data(database, date_column)\n",
    "\n",
    "for categories in categorical_data:\n",
    "    database, categories = data_transform.change_type(database, categories, 'category')\n",
    "\n",
    "\n",
    "'''\n",
    "Dropping columns whose data consists of more than 50% of null values\n",
    "and filling in the null values for the other columns with null values\n",
    "'''\n",
    "\n",
    "df_info = db_utils.DataFrameInfo(database)\n",
    "df_transform = db_utils.DataFrameTransform(database)\n",
    "df_plot = db_utils.Plotter(database)\n",
    "\n",
    "for column in column_headings:\n",
    "    null_vals, null_percentage = df_info.missing(database, column)\n",
    "    if null_percentage > float(50):\n",
    "        database = database.drop(column, axis=1)\n",
    "\n",
    "database = database.sort_values(by=['sub_grade'])\n",
    "database['int_rate'] = database['int_rate'].ffill()\n",
    "database['funded_amount'] = database.loc[:, 'loan_amount']\n",
    "fill_values = {'collections_12_mths_ex_med': 0, 'term': database['term'].mode()[0]}\n",
    "database = df_transform.fill_null(database, values= fill_values)\n",
    "\n",
    "last_payment_date_list= db_utils.make_list(database, 'last_payment_date')\n",
    "last_credit_pull_date_list = db_utils.make_list(database, 'last_credit_pull_date')\n",
    "\n",
    "for index in range(54231):\n",
    "    if pd.isnull(last_payment_date_list[index]):\n",
    "        last_payment_date_list[index] = last_credit_pull_date_list[index]\n",
    "    \n",
    "    if pd.isnull(last_credit_pull_date_list[index]):\n",
    "        last_credit_pull_date_list[index] = last_payment_date_list[index]\n",
    "\n",
    "database['last_payment_date'] = last_payment_date_list\n",
    "database['last_credit_pull_date'] = last_credit_pull_date_list\n",
    "database = database.dropna(axis = 0)\n",
    "\n",
    "\n",
    "'''\n",
    "Finding the skew of the columns made of integers and floats in the\n",
    "dataframe\n",
    "'''\n",
    "\n",
    "unskewed_data = database.copy()\n",
    "\n",
    "original_skews = df_info.df_skew(database)\n",
    "skewed_data = database[[cols for cols, skews in original_skews.items() if skews > 2]]\n",
    "log_skewed_data = yeojohnson_skew = boxcox_skew = skewed_data.copy()\n",
    "\n",
    "log_skewed_data = df_transform.log_transform(log_skewed_data)\n",
    "yeojohnson_skew = df_transform.yeojohnson_transform(yeojohnson_skew)\n",
    "boxcox_skew = df_transform.boxcox_transform(boxcox_skew)\n",
    "\n",
    "log_skew = df_info.df_skew(log_skewed_data)\n",
    "yeo_skew = df_info.df_skew(yeojohnson_skew)\n",
    "box_skew = df_info.df_skew(boxcox_skew)\n",
    "\n",
    "for column in skewed_data.columns:\n",
    "    col_skew = abs(original_skews.get(column))\n",
    "    log_col_skew = abs(log_skew[column])\n",
    "    yeo_col_skew = abs(yeo_skew[column])\n",
    "    \n",
    "    smallest_skew = min(log_col_skew, yeo_col_skew, col_skew)\n",
    "\n",
    "    if column in boxcox_skew.columns:\n",
    "        box_col_skew = abs(box_skew[column]).all()\n",
    "        \n",
    "        if box_col_skew <= smallest_skew:\n",
    "            unskewed_data.loc[:, column] = boxcox_skew[column].copy()\n",
    "\n",
    "    if smallest_skew == log_col_skew or smallest_skew == log_col_skew == yeo_col_skew:\n",
    "        unskewed_data.loc[:, column] = log_skewed_data[column].copy()\n",
    "    elif smallest_skew == yeo_col_skew:\n",
    "        unskewed_data.loc[:, column] = yeojohnson_skew[column].copy()\n",
    "\n",
    "'''\n",
    "Finding and removing outliers in the data.\n",
    "'''\n",
    "\n",
    "for categories in unskewed_data.columns:\n",
    "    if unskewed_data.dtypes[categories] in ['float64', 'int64']:\n",
    "        \n",
    "        q1 = unskewed_data[categories].quantile(0.25)\n",
    "        q3 = unskewed_data[categories].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        unskewed_data = unskewed_data[~((unskewed_data[categories]<(q1-1.5*iqr)) | (unskewed_data[categories]>(q3+1.5*iqr)))]\n",
    "        unskewed_data = unskewed_data.dropna().reset_index(drop=True)\n",
    "        z = np.abs(stats.zscore(unskewed_data[categories]))\n",
    "        unskewed_data = unskewed_data[np.abs(stats.zscore(unskewed_data[categories])) < 3]\n",
    "        #df_plot.plot_boxplot(unskewed_data, categories)\n",
    "\n",
    "fig = px.imshow(unskewed_data.corr(), title = 'Correlation heatmap of data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
